{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6baad41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\diosilva\\anaconda3\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: py4j==0.10.9.3 in c:\\users\\diosilva\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.3)\n",
      "Requirement already satisfied: findspark in c:\\users\\diosilva\\anaconda3\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "# instalando pacotes necessários\n",
    "!pip install pyspark\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c22bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicia o findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "534c19b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os módulos necessários\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf8f833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o contexto do spark\n",
    "sc = SparkContext()\n",
    "\n",
    "# Instancia o criador de sessao do spark\n",
    "spark = (SparkSession.builder\n",
    "                     .master('local[7]')\n",
    "                     .appName('Aceleração Pyspark - Capgemini'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa795a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria os schemas\n",
    "schema_airports = StructType([\n",
    "    StructField(\"faa\",  StringType(),  True),\n",
    "    StructField(\"name\", StringType(),  True),\n",
    "    StructField(\"lat\",  FloatType(),   True),\n",
    "    StructField(\"lon\",  FloatType(),   True),\n",
    "    StructField(\"alt\",  IntegerType(), True),\n",
    "    StructField(\"tz\",   IntegerType(), True),\n",
    "    StructField(\"dst\",  StringType(),  True)\n",
    "])\n",
    "\n",
    "schema_planes = StructType([\n",
    "    StructField(\"tailnum\",      StringType(),  True),\n",
    "    StructField(\"year\",         IntegerType(), True),\n",
    "    StructField(\"type\",         StringType(),  True),\n",
    "    StructField(\"manufacturer\", StringType(),  True),\n",
    "    StructField(\"model\",        StringType(),  True),\n",
    "    StructField(\"engines\",      IntegerType(), True),\n",
    "    StructField(\"seats\",        IntegerType(), True),\n",
    "    StructField(\"speed\",        IntegerType(), True),\n",
    "    StructField(\"engine\",       StringType(),  True)\n",
    "])\n",
    "\n",
    "schema_flights = StructType([\n",
    "    StructField(\"year\",      IntegerType(), True),\n",
    "    StructField(\"month\",     IntegerType(), True),\n",
    "    StructField(\"day\",       IntegerType(), True),\n",
    "    StructField(\"dep_time\",  StringType(),  True),\n",
    "    StructField(\"dep_delay\", IntegerType(), True),\n",
    "    StructField(\"arr_time\",  StringType(),  True),\n",
    "    StructField(\"arr_delay\", IntegerType(), True),\n",
    "    StructField(\"carrier\",   StringType(),  True),\n",
    "    StructField(\"tailnum\",   StringType(),  True),\n",
    "    StructField(\"flight\",    StringType(),  True),\n",
    "    StructField(\"origin\",    StringType(),  True),\n",
    "    StructField(\"dest\",      StringType(),  True),\n",
    "    StructField(\"air_time\",  IntegerType(), True),\n",
    "    StructField(\"distance\",  IntegerType(), True),\n",
    "    StructField(\"hour\",      IntegerType(), True),\n",
    "    StructField(\"minute\",    IntegerType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a54c85",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/C:/Users/diosilva/OneDrive - Capgemini/Documents/capgemini-aceleracao-pyspark/notebooks/data/airports.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22704/2477636705.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Cria todos os dataframes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m df_airports = (spark.getOrCreate().read\n\u001b[0m\u001b[0;32m      3\u001b[0m                   \u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                   \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"header\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"true\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                   \u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mschema_airports\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark-3.2.1-bin-hadoop2.7\\python\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark-3.2.1-bin-hadoop2.7\\python\\lib\\py4j-0.10.9.3-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark-3.2.1-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Path does not exist: file:/C:/Users/diosilva/OneDrive - Capgemini/Documents/capgemini-aceleracao-pyspark/notebooks/data/airports.csv"
     ]
    }
   ],
   "source": [
    "# Cria todos os dataframes\n",
    "df_airports = (spark.getOrCreate().read\n",
    "                  .format(\"csv\")\n",
    "                  .option(\"header\", \"true\")\n",
    "                  .schema(schema_airports)\n",
    "                  .load(\"./data/airports.csv\"))\n",
    "\n",
    "df_planes = (spark.getOrCreate().read\n",
    "                  .format(\"csv\")\n",
    "                  .option(\"header\", \"true\")\n",
    "                  .schema(schema_planes)\n",
    "                  .load(\"./data/planes.csv\"))\n",
    "\n",
    "df_flights = (spark.getOrCreate().read\n",
    "                  .format(\"csv\")\n",
    "                  .option(\"header\", \"true\")\n",
    "                  .schema(schema_flights)\n",
    "                  .load(\"./data/flights.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airports.show(3)\n",
    "df_planes.show(3)\n",
    "df_flights(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832bad2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
